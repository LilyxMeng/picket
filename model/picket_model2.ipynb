{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "picket-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "6F7YtWRDAXmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "classes =  [\"cardboard\", \"glass\", \"metal\", \"paper\", \"plastic\", \"trash\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "Rz9IOCIQAjsU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "#!ls gdrive/MyDrive/picketdataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "sNXqfEQcBco-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbb3d47-882f-446a-f9bd-45e27fc1ce90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pathlib\n",
        "dataset_url = r\".../model/Garbage-classification\"\n",
        "#data_dir = tf.keras.utils.get_file('Garbage-classification', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(dataset_url)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9OYQ2my8E5fi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkXKvdBYtTwv",
        "outputId": "ddfc9b24-d7a5-491d-e97d-2db6bc0ddc4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "batch_size = 32\n",
        "img_height = 512\n",
        "img_width = 384\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btlk3gWAtTpc",
        "outputId": "9cd283b1-b12c-4639-d1ce-ef7b45b9a2d3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1krZt7AtTj2",
        "outputId": "ef61d670-5ced-4bc8-a93e-31f2ecdb05bb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUOI-LtvtTf1",
        "outputId": "568cc7d0-d74a-4154-dcdc-7caca41779b6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "LfMz8KRjt8ks",
        "outputId": "dda20221-363c-4357-9df5-2fbf1eba73f8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOlbjoFjt8bp",
        "outputId": "b77629ac-aa90-4ff4-94cc-7dfe0c85ec4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "outputs": [],
      "metadata": {
        "id": "y5yIdQJvu4Ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Esy7MTfVu_P8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDGTZN-gyDXv",
        "outputId": "8da8e7fa-38ad-4b94-c9f9-79e940052ae1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "num_classes = 6\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "outputs": [],
      "metadata": {
        "id": "AkTN7glRyDNy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Jzq6aK46yDEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF2VBb0pu_rl",
        "outputId": "379fc145-58db-48c2-c71f-22e10f1d43eb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCFEUCt1zsTM",
        "outputId": "8aad4d8f-7bc8-4129-b0e0-f321a913af99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "3YIHWcIlzsNQ",
        "outputId": "2c52f223-5abb-44b4-ee06-506a4d6f1b29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "ohapU5yJzsGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "DWzdaRqKzr8p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#dont go further down lol"
      ],
      "outputs": [],
      "metadata": {
        "id": "9hir_1T6u8Ft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "root_dir = Path(\"gdrive/MyDrive/picketdataset/Garbage-classification\")\n",
        "\n",
        "training = []\n",
        "training_ids = []\n",
        "testing = []\n",
        "testing_ids = []\n",
        "\n",
        "for classe in classes:\n",
        "    class_id = classes.index(classe) #for each in classes list, find the index of it\n",
        "    files = root_dir.glob(\"{classe}/*.jpg\".format(classe=classe)) #iterate through all class folders to get imgs\n",
        "    files = sorted(files) #turn them to sorted list\n",
        "    for file in files[:len(files)*4//5]: #split the data into 4/5 training\n",
        "        with open(file, 'rb') as f:\n",
        "            if plt.imread(f).T.shape == (3, 512, 384):\n",
        "                training.append(plt.imread(f)) #add the image transposed into (384, 512, 3)\n",
        "                training_ids.append(class_id) #append corresponding picture to training labels\n",
        "\n",
        "    for file2 in files[len(files)*4//5:]: #split data into 1/5 traing\n",
        "        with open(file2, 'rb') as f2:\n",
        "            if plt.imread(f2).T.shape == (3, 512, 384):\n",
        "                testing.append(plt.imread(f2))\n",
        "                testing_ids.append(class_id)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i_WMdOj7Aolw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "2035b2fc-1b10-4639-fbf1-ec3b6901257c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3XQ0APhEiwI",
        "outputId": "a697427f-c7ae-4978-882a-efc04ed82db4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#print(training[0].T.shape)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_74Nig8eEkpJ",
        "outputId": "a0cd6120-0753-42b8-ea55-9c01b6902dd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training_files = []\n",
        "for train_file in training:\n",
        "  training_files.append(train_file.T)\n",
        "\n",
        "testing_files = []\n",
        "for test_file in testing:\n",
        "  testing_files.append(test_file.T)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kKe3ztwWH5wF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#print(len(training_files))\n",
        "#print(len(testing_files))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKnqaqhPIVes",
        "outputId": "3b98b372-1cb0-4af1-bf65-9acfe34794a1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training = np.asarray(training_files)\n",
        "testing = np.asarray(testing_files)"
      ],
      "outputs": [],
      "metadata": {
        "id": "de7yxjYQInK2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training.shape\n",
        "testing.shape"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptBTScrFI1my",
        "outputId": "26027b19-7821-485b-a97c-7b0ba4a158f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(classes[training_ids[500]])\n",
        "plt.imshow(training[500])\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "iCSNwr6gJ0EU",
        "outputId": "3644c135-1066-40bf-fa08-b6228c4d86fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "p7UXjjpFKNuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#np.save(\"gdrive/MyDrive/picketdataset/trainimgs.npy\", training)\n",
        "\n",
        "#np.save(\"gdrive/MyDrive/picketdataset/testimgs.npy\", testing)\n",
        "\n",
        "#np.save(\"gdrive/MyDrive/picketdataset/trainlabels.npy\", training_ids)\n",
        "\n",
        "#np.save(\"gdrive/MyDrive/picketdataset/testlabels.npy\", testing_ids)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4Yps6Rg8I4QM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training_loaded = np.load(\"gdrive/MyDrive/picketdataset/trainimgs.npy\", mmap_mode=\"r\")\n",
        "\n",
        "testing_loaded = np.load(\"gdrive/MyDrive/picketdataset/testimgs.npy\", mmap_mode=\"r\")\n",
        "\n",
        "trainids_loaded = np.load(\"gdrive/MyDrive/picketdataset/trainlabels.npy\", mmap_mode=\"r\")\n",
        "\n",
        "testids_loaded = np.load(\"gdrive/MyDrive/picketdataset/testlabels.npy\", mmap_mode=\"r\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "cnng3Ru4QZn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training_loaded.shape\n",
        "testing_loaded.shape"
      ],
      "outputs": [],
      "metadata": {
        "id": "EGhb4ja2LQvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda6ca5b-4f23-4d9a-c823-98e7e0e8757d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "hYZFnxdLrtw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "opD2S6JPrtoO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "LR3MSDHLrtc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "###dont go down"
      ],
      "outputs": [],
      "metadata": {
        "id": "ciDMCYT8rr6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "OSgLk4scMBqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "res_model = torchvision.models.resnet18(pretrained=True)\n",
        "newmodel = torch.nn.Sequential(*(list(res_model.children())[:-1]))\n",
        "newmodel.eval();"
      ],
      "outputs": [],
      "metadata": {
        "id": "BrduiMPJNi_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x_std.shape"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-CYGul2mTXy",
        "outputId": "56bb0e27-4e44-40ad-a1ec-31837515c09a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x_mean = []\n",
        "x_std = []\n",
        "\n",
        "for batch_cnt in range(3):\n",
        "    x_mean.append(np.mean(training_loaded[batch_cnt * 673: (batch_cnt + 1) * 673], axis=0))\n",
        "    x_std.append(np.std(training_loaded[batch_cnt * 673: (batch_cnt + 1) * 673], axis= 0))\n",
        "x_mean = np.mean(x_mean, axis=0)\n",
        "x_std = np.mean(x_std, axis=0)\n",
        "x_mean = np.mean(x_mean, axis=(1,2))\n",
        "x_std = np.mean(x_std, axis=(1,2))\n",
        "\n",
        "\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Model that converts a shape (N, 512) descriptor vector for N images into a shape (N, 25) \n",
        "    array of classification scores for each of the N images.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense1 = nn.Linear(512, 100)\n",
        "        self.dense2 = nn.Linear(100, 25)\n",
        "        self.relu = nn.ReLU()\n",
        "  \n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: shape (N, 512) descriptor vector for N images. Use resnet to convert images into image descriptors\n",
        "        \n",
        "        Returns\n",
        "        --------\n",
        "        Classification scores for each of the N images. shape (N, 25)\n",
        "        \"\"\"\n",
        "        out1 = self.relu(self.dense1(x))\n",
        "        return self.dense2(out1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "JEaXy91uEOqD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "newmodel.to('cuda')\n",
        "newmodel.eval()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ns-VRUNRGUP",
        "outputId": "b76e632e-1189-4d1e-840b-f9da903c2237"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "last_layer = LinearModel()\n",
        "last_layer.to('cuda')\n",
        "optim = torch.optim.Adam(last_layer.parameters())\n",
        "\n",
        "def accuracy(predictions, truth):\n",
        "    \"\"\"\n",
        "    Returns the mean classification accuracy for a batch of predictions.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    predictions : Union[numpy.ndarray, mg.Tensor], shape=(M, D)\n",
        "        The scores for D classes, for a batch of M data points\n",
        "    truth : numpy.ndarray, shape=(M,)\n",
        "        The true labels for each datum in the batch: each label is an\n",
        "        integer in [0, D)\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "    \"\"\"\n",
        "    return np.mean(np.argmax(predictions, axis=1) == truth) # <COGLINE>\n",
        "\n",
        "from statistics import mean\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "imSw0ePHRQb4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training_loaded[batch_indices].shape\n",
        "def norm(x_arr, mean, std):\n",
        "    N = len(x_arr)\n",
        "    print((np.repeat(mean, N)).shape)\n",
        "    return (x_arr - (np.repeat(mean, N).reshape(N, 3, 1, 1))) / np.repeat(std, N).reshape(N, 3, 1, 1)\n",
        "\n",
        "from sklearn import preprocessing"
      ],
      "outputs": [],
      "metadata": {
        "id": "HsakU0dPSw1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "##training\n",
        "batch_size = 10\n",
        "idxs_y = np.arange(len(testing_loaded))\n",
        "for epoch_cnt in range(7):\n",
        "    idxs = np.arange(len(training_loaded))  # -> array([0, 1, ..., 9999])\n",
        "    np.random.shuffle(idxs)\n",
        "    accs = []\n",
        "    print(\"epoch: \" + str(epoch_cnt + 1))\n",
        "    \n",
        "    for batch_cnt in range(0, len(training_loaded)//batch_size):\n",
        "        batch_indices = idxs[batch_cnt*batch_size : (batch_cnt + 1)*batch_size]\n",
        "        \n",
        "        batch = torch.tensor(training_loaded[batch_indices], dtype=torch.float).to('cuda')  # random batch of our training data\n",
        "        truth = torch.tensor(trainids_loaded[batch_indices], dtype=torch.long).to('cuda')\n",
        "        \n",
        "\n",
        "        # `model.__call__ is responsible for performing the \"forward-pass\"\n",
        "        #print(type(torch.tensor(batch).float()))\n",
        "        features = newmodel(batch)\n",
        "        prediction = last_layer(features.reshape(batch_size, 512))\n",
        "        \n",
        "        #calculate loss\n",
        "        loss_function = nn.CrossEntropyLoss()\n",
        "        loss = loss_function(prediction, truth)\n",
        "        loss.backward()\n",
        "        \n",
        "        # the optimizer is responsible for updating all of the parameters\n",
        "        optim.step()\n",
        "        \n",
        "        # we'll also compute the accuracy of our model as usual\n",
        "        acc = accuracy(prediction.cpu().detach().numpy(), truth.cpu().detach().numpy()) #take tensor, strip grad, convert numpy\n",
        "        optim.zero_grad()\n",
        "\n",
        "        if batch_cnt % 10 == 0:\n",
        "          print(\"loss: \" + str(loss.item()))\n",
        "          print(\"accuracy: \" + str(acc))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "4cqI0qgmRjFW",
        "outputId": "09a7fb5f-a13d-4e52-bad0-2cc05d15dd4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "DqhNOFaTTWL6"
      }
    }
  ]
}